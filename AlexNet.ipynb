{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AlexNet.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1mhGsctWNrfANRveQ1WeKFBFS8agNOtPp","authorship_tag":"ABX9TyOjmT16OJX8UXvvg7Q/58Ac"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install torchmetrics\n","!pip install pytorch_lightning"],"metadata":{"id":"EPnjDr2EAvLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":1,"metadata":{"id":"-kYftslnl4F3","executionInfo":{"status":"ok","timestamp":1651617277991,"user_tz":300,"elapsed":4056,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}}},"outputs":[],"source":["import collections\n","import copy\n","import os\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import torch\n","import torch.nn as nn\n","from absl import app, flags\n","from skimage import io\n","from torch.utils.data import DataLoader, Dataset\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import transforms\n","from tqdm import tqdm\n","\n","FLAGS = flags.FLAGS\n","\n","flags.DEFINE_enum('task_type', 'training', ['training', 'analysis'],\n","                  'Specifies the task type.')\n","\n","# Hyperparameters for Part I\n","flags.DEFINE_float('learning_rate', 1e-3, 'Learning rate.')\n","flags.DEFINE_float('weight_decay', 0, 'Weight decay (L2 regularization).')\n","flags.DEFINE_integer('batch_size', 128, 'Number of examples per batch.')\n","flags.DEFINE_integer('epochs', 100, 'Number of epochs for training.')\n","flags.DEFINE_string('experiment_name', 'exp', 'Defines experiment name.')\n","flags.DEFINE_enum('label_type', 'domain', ['domain', 'category'],\n","                  'Specifies prediction task.')\n","\n","# Hyperparemeters for Part III\n","flags.DEFINE_string('model_checkpoint', '',\n","                    'Specifies the checkpont for analyzing.')\n","\n","LABEL_SIZE = {'domain': 4, 'category': 7}\n","\n"]},{"cell_type":"code","source":["import torchmetrics\n","from torch.utils.data import DataLoader\n","from torchvision import transforms\n","from torchvision.datasets import ImageFolder\n","from torch import nn, optim\n","import pytorch_lightning as pl\n","from pytorch_lightning.callbacks import ModelCheckpoint"],"metadata":{"id":"5sjbGjihBfmI","executionInfo":{"status":"ok","timestamp":1651617282616,"user_tz":300,"elapsed":610,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["# **1. Implement AlexNet**"],"metadata":{"id":"MU2WkC0hrZBB"}},{"cell_type":"markdown","source":["**PACSDataset**"],"metadata":{"id":"lnpNypA6reCy"}},{"cell_type":"code","source":["class PACSDataset(Dataset):\n","\n","  def __init__(self,\n","               root_dir,\n","               label_type='domain',\n","               is_training=False,\n","               transform=None):\n","    self.root_dir = os.path.join(root_dir, 'train' if is_training else 'val')\n","    self.label_type = label_type\n","    self.is_training = is_training\n","    if transform:\n","      self.transform = transform\n","    else:\n","      self.transform = transforms.Compose([\n","          transforms.ToTensor(),\n","          transforms.Normalize(mean=[0.7659, 0.7463, 0.7173],\n","                               std=[0.3089, 0.3181, 0.3470]),\n","      ])\n","\n","    self.dataset, self.label_list = self.initialize_dataset()\n","    self.label_to_id = {x: i for i, x in enumerate(self.label_list)}\n","    self.id_to_label = {i: x for i, x in enumerate(self.label_list)}\n","\n","  def __len__(self):\n","    return len(self.dataset)\n","\n","  def __getitem__(self, idx):\n","    image, label = self.dataset[idx]\n","    label_id = self.label_to_id[label]\n","    image = self.transform(image)\n","    return image, label_id\n","\n","  def initialize_dataset(self):\n","    assert os.path.isdir(self.root_dir), \\\n","        '`root_dir` is not found at %s' % self.root_dir\n","\n","    dataset = []\n","    domain_set = set()\n","    category_set = set()\n","    cnt = 0\n","\n","    for root, dirs, files in os.walk(self.root_dir, topdown=True):\n","      if files:\n","        _, domain, category = root.rsplit('/', maxsplit=2)\n","        domain_set.add(domain)\n","        category_set.add(category)\n","        pbar = tqdm(files)\n","        for name in pbar:\n","          pbar.set_description('Processing Folder: domain=%s, category=%s' %\n","                               (domain, category))\n","          img_array = io.imread(os.path.join(root, name))\n","          dataset.append((img_array, domain, category))\n","\n","    images, domains, categories = zip(*dataset)\n","\n","    if self.label_type == 'domain':\n","      labels = sorted(domain_set)\n","      dataset = list(zip(images, domains))\n","    elif self.label_type == 'category':\n","      labels = sorted(category_set)\n","      dataset = list(zip(images, categories))\n","    else:\n","      raise ValueError(\n","          'Unknown `label_type`: Expecting `domain` or `category`.')\n","\n","    return dataset, labels\n"],"metadata":{"id":"lOlcvRVMmEb4","executionInfo":{"status":"ok","timestamp":1651617285432,"user_tz":300,"elapsed":146,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["**AlexNet**"],"metadata":{"id":"h4jsFQtvrs72"}},{"cell_type":"code","source":["class AlexNet(nn.Module):\n","\n","  def __init__(self, configs):\n","    super().__init__()\n","    self.configs = configs\n","    super().__init__()\n","    act_func = nn.ReLU()\n","    self.loss = nn.CrossEntropyLoss()\n","    self.lr = float(1e-3)\n","    self.dropout = 0.2\n","    self.train_acc = torchmetrics.Accuracy()\n","    self.val_acc = torchmetrics.Accuracy()\n","    self.features = nn.Sequential(\n","        nn.Conv2d(3, 96, kernel_size=11, stride=4),\n","        act_func,\n","        nn.MaxPool2d(kernel_size=3, stride=2),\n","        nn.Conv2d(96, 256, kernel_size=5, padding=2),\n","        act_func,\n","        nn.MaxPool2d(kernel_size=3, stride=2),\n","        nn.Conv2d(256, 384, kernel_size=3, padding=1),\n","        act_func,\n","        nn.Conv2d(384, 384, kernel_size=3, padding=1),\n","        act_func,\n","        nn.Conv2d(384, 256, kernel_size=3, padding=1),\n","        act_func,\n","        nn.MaxPool2d(kernel_size=3, stride=2),\n","    )\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(-1),\n","        nn.Dropout(self.dropout),\n","        nn.Linear(9216, 4096),\n","        act_func,\n","        nn.Dropout(self.dropout),\n","        nn.Linear(4096, 4096),\n","        act_func,\n","        nn.Linear(4096, 28),\n","    )\n","\n","  def forward(self, X):\n","      X = self.features(X)\n","      batch_size, _, _, _ = X.size()\n","      X = X.view(batch_size, -1)\n","      X = self.classifier(X)\n","      return X\n"],"metadata":{"id":"nDglYe8O_BJA","executionInfo":{"status":"ok","timestamp":1651617288609,"user_tz":300,"elapsed":178,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def model_training(model, root_dir, label_type, batch_size, max_epochs, learning_rate, weight_decay, experiment_name):\n","  train_dataset = PACSDataset(root_dir=root_dir,\n","                              label_type=label_type,\n","                              is_training=True)\n","  train_loader = DataLoader(train_dataset,\n","                            batch_size=batch_size,\n","                            shuffle=True,\n","                            num_workers=4)\n","\n","  val_dataset = PACSDataset(root_dir=root_dir,\n","                            label_type=label_type,\n","                            is_training=False)\n","  val_loader = DataLoader(val_dataset,\n","                          batch_size=batch_size,\n","                          shuffle=False,\n","                          num_workers=4)\n","\n","  best_model = None\n","  best_acc = 0.0\n","\n","  experiment_name = 'experiments/{}/{}_lr_{}.wd_{}'.format(\n","      experiment_name, label_type, learning_rate,\n","      weight_decay)\n","\n","  os.makedirs(experiment_name, exist_ok=True)\n","  writer = SummaryWriter(log_dir=experiment_name)\n","\n","  ############################################################################\n","  \"\"\"After implementing all required models, you can switch from here.\"\"\"\n","  # model = AlexNet(configs).to(device)\n","  # model = AlexNetLargeKernel(configs).to(device)\n","  # model = AlexNetAvgPooling(configs).to(device)\n","  ############################################################################\n","\n","  print('Model Architecture:\\n%s' % model)\n","\n","  criterion = nn.CrossEntropyLoss(reduction='mean')\n","  optimizer = torch.optim.Adam(model.parameters(),\n","                               lr=learning_rate,\n","                               weight_decay=weight_decay)\n","\n","  try:\n","    for epoch in range(max_epochs):\n","      for phase in ('train', 'eval'):\n","        if phase == 'train':\n","          model.train()\n","          dataset = train_dataset\n","          data_loader = train_loader\n","        else:\n","          model.eval()\n","          dataset = val_dataset\n","          data_loader = val_loader\n","\n","        running_loss = 0.0\n","        running_corrects = 0\n","\n","        for step, (images, labels) in enumerate(data_loader):\n","          images = images.to(device)\n","          labels = labels.to(device)\n","\n","          optimizer.zero_grad()\n","\n","          with torch.set_grad_enabled(phase == 'train'):\n","            outputs = model(images)\n","            _, preds = torch.max(outputs, 1)\n","            loss = criterion(outputs, labels)\n","\n","            if phase == 'train':\n","              loss.backward()\n","              optimizer.step()\n","\n","              writer.add_scalar('Loss/{}'.format(phase), loss.item(),\n","                                epoch * len(data_loader) + step)\n","\n","          running_loss += loss.item() * images.size(0)\n","          running_corrects += torch.sum(preds == labels.data)\n","\n","        epoch_loss = running_loss / len(dataset)\n","        epoch_acc = running_corrects.double() / len(dataset)\n","        writer.add_scalar('Epoch_Loss/{}'.format(phase), epoch_loss, epoch)\n","        writer.add_scalar('Epoch_Accuracy/{}'.format(phase), epoch_acc, epoch)\n","        print('[Epoch %d] %s accuracy: %.4f, loss: %.4f' %\n","              (epoch + 1, phase, epoch_acc, epoch_loss))\n","\n","        if phase == 'eval':\n","          if epoch_acc > best_acc:\n","            best_acc = epoch_acc\n","            best_model = copy.deepcopy(model.state_dict())\n","            torch.save(best_model, os.path.join(experiment_name,\n","                                                'best_model.pt'))\n","\n","  except KeyboardInterrupt:\n","    pass\n","\n","  return model"],"metadata":{"id":"OhqrU6T9DyI8","executionInfo":{"status":"ok","timestamp":1651617291113,"user_tz":300,"elapsed":164,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}}},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":["**predicting domain**"],"metadata":{"id":"zh1FVXTmqPAA"}},{"cell_type":"code","source":["root_dir='/content/drive/MyDrive/DL/HW2/pacs_dataset'\n","\n","LABEL_SIZE = {'domain': 4, 'category': 7}\n","label_type = 'domain'\n","epochs = 50\n","lr=1e-3\n","weight_decay=0\n","batch_size=128\n","experiment_name= 'exp'\n","\n","configs = {'num_classes': LABEL_SIZE[label_type]}\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","alexnet_domain = model_training(model= AlexNet(configs).to(device), \n","                                root_dir=root_dir, \n","                                label_type=label_type, \n","                                batch_size=batch_size, \n","                                max_epochs=epochs, \n","                                learning_rate=lr, \n","                                weight_decay=weight_decay,\n","                                experiment_name=experiment_name)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GrTVQzYBgJro","outputId":"b7102c8d-c858-4991-d1ae-3bc3f83b101e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Folder: domain=photo, category=dog: 100%|██████████| 169/169 [00:03<00:00, 48.40it/s]\n","Processing Folder: domain=photo, category=elephant: 100%|██████████| 181/181 [00:03<00:00, 56.98it/s]\n","Processing Folder: domain=photo, category=giraffe: 100%|██████████| 165/165 [00:03<00:00, 53.56it/s]\n","Processing Folder: domain=photo, category=horse: 100%|██████████| 186/186 [00:03<00:00, 55.67it/s]\n","Processing Folder: domain=photo, category=guitar: 100%|██████████| 167/167 [00:03<00:00, 53.46it/s]\n","Processing Folder: domain=photo, category=house: 100%|██████████| 243/243 [00:04<00:00, 51.98it/s]\n","Processing Folder: domain=photo, category=person: 100%|██████████| 383/383 [00:06<00:00, 56.12it/s]\n","Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 254/254 [00:07<00:00, 34.77it/s]\n","Processing Folder: domain=art_painting, category=house: 100%|██████████| 262/262 [00:05<00:00, 51.97it/s]\n","Processing Folder: domain=art_painting, category=dog: 100%|██████████| 348/348 [00:06<00:00, 54.34it/s]\n","Processing Folder: domain=art_painting, category=person: 100%|██████████| 404/404 [00:07<00:00, 52.86it/s]\n","Processing Folder: domain=art_painting, category=horse: 100%|██████████| 179/179 [00:02<00:00, 60.29it/s]\n","Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 227/227 [00:04<00:00, 53.36it/s] \n","Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 169/169 [00:02<00:00, 62.31it/s]\n","Processing Folder: domain=sketch, category=elephant: 100%|██████████| 674/674 [00:22<00:00, 30.22it/s] \n","Processing Folder: domain=sketch, category=guitar: 100%|██████████| 564/564 [00:11<00:00, 50.89it/s]\n","Processing Folder: domain=sketch, category=dog: 100%|██████████| 697/697 [00:14<00:00, 48.72it/s]\n","Processing Folder: domain=sketch, category=horse: 100%|██████████| 736/736 [00:20<00:00, 35.80it/s]\n","Processing Folder: domain=sketch, category=house: 100%|██████████| 75/75 [00:20<00:00,  3.61it/s]\n","Processing Folder: domain=sketch, category=person: 100%|██████████| 143/143 [00:02<00:00, 56.51it/s]\n","Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 681/681 [00:13<00:00, 50.18it/s] \n","Processing Folder: domain=cartoon, category=dog: 100%|██████████| 343/343 [00:07<00:00, 45.15it/s] \n","Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 314/314 [00:05<00:00, 55.54it/s] \n","Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 411/411 [00:07<00:00, 52.43it/s]\n","Processing Folder: domain=cartoon, category=horse: 100%|██████████| 299/299 [00:07<00:00, 37.85it/s]\n","Processing Folder: domain=cartoon, category=person: 100%|██████████| 364/364 [00:06<00:00, 58.59it/s] \n","Processing Folder: domain=cartoon, category=house: 100%|██████████| 266/266 [00:04<00:00, 55.62it/s]\n","Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 123/123 [00:02<00:00, 49.40it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Processing Folder: domain=art_painting, category=dog: 100%|██████████| 31/31 [00:08<00:00,  3.72it/s]\n","Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 28/28 [00:07<00:00,  3.54it/s]\n","Processing Folder: domain=art_painting, category=horse: 100%|██████████| 22/22 [00:05<00:00,  3.70it/s]\n","Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 31/31 [00:08<00:00,  3.75it/s]\n","Processing Folder: domain=art_painting, category=house: 100%|██████████| 33/33 [00:09<00:00,  3.54it/s]\n","Processing Folder: domain=art_painting, category=person: 100%|██████████| 45/45 [00:12<00:00,  3.59it/s]\n","Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 15/15 [00:03<00:00,  4.06it/s]\n","Processing Folder: domain=cartoon, category=dog: 100%|██████████| 46/46 [00:12<00:00,  3.54it/s]\n","Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 12/12 [00:03<00:00,  3.46it/s]\n","Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 32/32 [00:08<00:00,  3.58it/s]\n","Processing Folder: domain=cartoon, category=horse: 100%|██████████| 25/25 [00:09<00:00,  2.69it/s]\n","Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 46/46 [00:12<00:00,  3.71it/s]\n","Processing Folder: domain=cartoon, category=person: 100%|██████████| 41/41 [00:11<00:00,  3.57it/s]\n","Processing Folder: domain=cartoon, category=house: 100%|██████████| 22/22 [00:06<00:00,  3.37it/s]\n","Processing Folder: domain=photo, category=dog: 100%|██████████| 20/20 [00:05<00:00,  3.43it/s]\n","Processing Folder: domain=photo, category=elephant: 100%|██████████| 21/21 [00:05<00:00,  3.66it/s]\n","Processing Folder: domain=photo, category=person: 100%|██████████| 49/49 [00:13<00:00,  3.51it/s]\n","Processing Folder: domain=photo, category=guitar: 100%|██████████| 19/19 [00:05<00:00,  3.62it/s]\n","Processing Folder: domain=photo, category=giraffe: 100%|██████████| 17/17 [00:04<00:00,  3.48it/s]\n","Processing Folder: domain=photo, category=house: 100%|██████████| 37/37 [00:10<00:00,  3.57it/s]\n","Processing Folder: domain=photo, category=horse: 100%|██████████| 13/13 [00:03<00:00,  3.64it/s]\n","Processing Folder: domain=sketch, category=dog: 100%|██████████| 75/75 [00:20<00:00,  3.67it/s]\n","Processing Folder: domain=sketch, category=guitar: 100%|██████████| 44/44 [00:12<00:00,  3.57it/s]\n","Processing Folder: domain=sketch, category=person: 100%|██████████| 17/17 [00:04<00:00,  3.74it/s]\n","Processing Folder: domain=sketch, category=house: 100%|██████████| 5/5 [00:01<00:00,  3.63it/s]\n","Processing Folder: domain=sketch, category=elephant: 100%|██████████| 66/66 [00:18<00:00,  3.57it/s]\n","Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 72/72 [00:19<00:00,  3.64it/s]\n","Processing Folder: domain=sketch, category=horse: 100%|██████████| 80/80 [00:22<00:00,  3.55it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Model Architecture:\n","AlexNet(\n","  (loss): CrossEntropyLoss()\n","  (train_acc): Accuracy()\n","  (val_acc): Accuracy()\n","  (features): Sequential(\n","    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU()\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU()\n","    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU()\n","    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU()\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=-1, end_dim=-1)\n","    (1): Dropout(p=0.2, inplace=False)\n","    (2): Linear(in_features=9216, out_features=4096, bias=True)\n","    (3): ReLU()\n","    (4): Dropout(p=0.2, inplace=False)\n","    (5): Linear(in_features=4096, out_features=4096, bias=True)\n","    (6): ReLU()\n","    (7): Linear(in_features=4096, out_features=28, bias=True)\n","  )\n",")\n","[Epoch 1] train accuracy: 0.5387, loss: 2.1079\n","[Epoch 1] eval accuracy: 0.7510, loss: 0.5115\n","[Epoch 2] train accuracy: 0.7675, loss: 0.4791\n","[Epoch 2] eval accuracy: 0.7759, loss: 0.4475\n","[Epoch 3] train accuracy: 0.8192, loss: 0.4176\n","[Epoch 3] eval accuracy: 0.8392, loss: 0.3797\n","[Epoch 4] train accuracy: 0.8447, loss: 0.3698\n","[Epoch 4] eval accuracy: 0.8620, loss: 0.3276\n","[Epoch 5] train accuracy: 0.8662, loss: 0.3220\n","[Epoch 5] eval accuracy: 0.8786, loss: 0.3217\n","[Epoch 6] train accuracy: 0.8732, loss: 0.3095\n","[Epoch 6] eval accuracy: 0.8693, loss: 0.3085\n"]}]},{"cell_type":"markdown","source":["**predicting class**"],"metadata":{"id":"s5nHkWa1qDya"}},{"cell_type":"code","source":["root_dir='/content/drive/MyDrive/DL/HW2/pacs_dataset'\n","\n","LABEL_SIZE = {'domain': 4, 'category': 7}\n","label_type = 'category'\n","epochs = 50\n","lr=1e-3\n","weight_decay=0\n","batch_size=128\n","experiment_name= 'exp'\n","\n","configs = {'num_classes': LABEL_SIZE[label_type]}\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","alexnet_category = model_training(model= AlexNet(configs).to(device), \n","                                root_dir=root_dir, \n","                                label_type=label_type, \n","                                batch_size=batch_size, \n","                                max_epochs=epochs, \n","                                learning_rate=lr, \n","                                weight_decay=weight_decay,\n","                                experiment_name=experiment_name)\n"],"metadata":{"id":"zzBdV-dvo5Z-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 2. Enhancing AlexNet"],"metadata":{"id":"97FE_ss8qm3V"}},{"cell_type":"markdown","source":["**AlexNetLargeKernel**"],"metadata":{"id":"iAbK3ECfr4ZV"}},{"cell_type":"code","source":["class AlexNetLargeKernel(nn.Module):\n","  def __init__(self, configs):\n","    \n","        super().__init__()\n","        self.configs = configs\n","        act_func = nn.ReLU()\n","        self.loss = nn.CrossEntropyLoss()\n","        self.lr = float(1e-3)\n","        self.dropout = 0.2\n","        self.train_acc = torchmetrics.Accuracy()\n","        self.val_acc = torchmetrics.Accuracy()\n","        self.features = nn.Sequential(\n","            nn.Conv2d(3, 96, kernel_size=21, padding=1, stride=8),\n","            act_func,\n","            nn.Conv2d(96, 256, kernel_size=7, padding=2, stride=2),\n","            act_func,\n","            nn.Conv2d(256, 384, kernel_size=3, padding=1),\n","            act_func,\n","            nn.Conv2d(384, 384, kernel_size=3, padding=1),\n","            act_func,\n","            nn.Conv2d(384, 256, kernel_size=3, stride=2),\n","            act_func,\n","            nn.MaxPool2d(kernel_size=3, stride=2),\n","        )\n","        self.classifier = nn.Sequential(\n","            nn.Flatten(-1),\n","            nn.Dropout(self.dropout),\n","            nn.Linear(1024, 4096),\n","            act_func,\n","            nn.Dropout(self.dropout),\n","            nn.Linear(4096, 4096),\n","            act_func,\n","            nn.Linear(4096, 28),\n","        )\n","\n","  def forward(self, X):\n","      X = self.features(X)\n","      batch_size, _, _, _ = X.size()\n","      X = X.view(batch_size, -1)\n","      X = self.classifier(X)\n","      return X\n"],"metadata":{"id":"T28KRTik_OWI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**AlexNetAvgPooling**"],"metadata":{"id":"ykYRcLGhr1hL"}},{"cell_type":"code","source":["class AlexNetAvgPooling(nn.Module):\n","  def __init__(self, configs):\n","    super().__init__()\n","    act_func = nn.ReLU()\n","    self.loss = nn.CrossEntropyLoss()\n","    self.lr = float(1e-3)\n","    self.dropout = 0.2\n","    self.train_acc = torchmetrics.Accuracy()\n","    self.val_acc = torchmetrics.Accuracy()\n","    self.features = nn.Sequential(\n","        nn.Conv2d(3, 96, kernel_size=11, stride=4),\n","        act_func,\n","        nn.AvgPool2d(3, 2),\n","        nn.Conv2d(96, 256, kernel_size=5, padding=2),\n","        act_func,\n","        nn.AvgPool2d(3, 2),\n","        nn.Conv2d(256, 384, kernel_size=3, padding=1),\n","        act_func,\n","        nn.Conv2d(384, 384, kernel_size=3, padding=1),\n","        act_func,\n","        nn.Conv2d(384, 256, kernel_size=3, stride=2),\n","        act_func,\n","        nn.MaxPool2d(kernel_size=3, stride=2),\n","    )\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(-1),\n","        nn.Dropout(self.dropout),\n","        nn.Linear(1024, 4096),\n","        act_func,\n","        nn.Dropout(self.dropout),\n","        nn.Linear(4096, 4096),\n","        act_func,\n","        nn.Linear(4096, 28),\n","        )\n","\n","  def forward(self, X):\n","      X = self.features(X)\n","      batch_size, _, _, _ = X.size()\n","      X = X.view(batch_size, -1)\n","      X = self.classifier(X)\n","      return X"],"metadata":{"id":"_QnZ6w2QCTjB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**predicting domain**"],"metadata":{"id":"0cfW2kiTq6TU"}},{"cell_type":"code","source":["alexnet_large_kernel_domain = model_training(model= AlexNetLargeKernel(configs).to(device), \n","                                root_dir=root_dir, \n","                                label_type=label_type, \n","                                batch_size=batch_size, \n","                                max_epochs=epochs, \n","                                learning_rate=lr, \n","                                weight_decay=weight_decay,\n","                                experiment_name=experiment_name)"],"metadata":{"id":"nJTG-NN5pdBX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["**predicting class**"],"metadata":{"id":"xIZFkc7gqxDx"}},{"cell_type":"code","source":["alexnet_large_kernel_category = model_training(model= AlexNetLargeKernel(configs).to(device), \n","                                root_dir=root_dir, \n","                                label_type=label_type, \n","                                batch_size=batch_size, \n","                                max_epochs=epochs, \n","                                learning_rate=lr, \n","                                weight_decay=weight_decay,\n","                                experiment_name=experiment_name)"],"metadata":{"id":"yThFVv1qqsM1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## New Section"],"metadata":{"id":"GS13YEZ1skbU"}},{"cell_type":"code","source":["root_dir='/content/drive/MyDrive/DL/HW2/pacs_dataset'\n","\n","'''# Hyperparameters for Part I\n","flags.DEFINE_float('learning_rate', 1e-3, 'Learning rate.')\n","flags.DEFINE_float('weight_decay', 0, 'Weight decay (L2 regularization).')\n","flags.DEFINE_integer('batch_size', 128, 'Number of examples per batch.')\n","flags.DEFINE_integer('epochs', 100, 'Number of epochs for training.')\n","flags.DEFINE_string('experiment_name', 'exp', 'Defines experiment name.')\n","flags.DEFINE_enum('label_type', 'domain', ['domain', 'category'],\n","                  'Specifies prediction task.')\n","                  \n","LABEL_SIZE = {'domain': 4, 'category': 7}'''\n","\n","train_dataset = PACSDataset(root_dir=root_dir,\n","                              label_type='domain',\n","                              is_training=True)\n","train_loader = DataLoader(train_dataset,\n","                          batch_size=128,\n","                          shuffle=True,\n","                          num_workers=4)\n","\n","val_dataset = PACSDataset(root_dir=root_dir,\n","                          label_type='domain',\n","                          is_training=False)\n","val_loader = DataLoader(val_dataset,\n","                        batch_size=128,\n","                        shuffle=False,\n","                        num_workers=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kVjll4Wqc1vI","executionInfo":{"status":"ok","timestamp":1651595354688,"user_tz":300,"elapsed":113507,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}},"outputId":"f5507622-2752-4242-ee8c-523cda4137a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Folder: domain=photo, category=dog: 100%|██████████| 169/169 [00:01<00:00, 93.31it/s]\n","Processing Folder: domain=photo, category=elephant: 100%|██████████| 181/181 [00:01<00:00, 97.15it/s]\n","Processing Folder: domain=photo, category=giraffe: 100%|██████████| 165/165 [00:02<00:00, 72.75it/s]\n","Processing Folder: domain=photo, category=horse: 100%|██████████| 186/186 [00:02<00:00, 80.78it/s]\n","Processing Folder: domain=photo, category=guitar: 100%|██████████| 167/167 [00:01<00:00, 102.69it/s]\n","Processing Folder: domain=photo, category=house: 100%|██████████| 243/243 [00:02<00:00, 96.06it/s]\n","Processing Folder: domain=photo, category=person: 100%|██████████| 383/383 [00:04<00:00, 91.19it/s]\n","Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 254/254 [00:03<00:00, 77.80it/s]\n","Processing Folder: domain=art_painting, category=house: 100%|██████████| 262/262 [00:02<00:00, 94.12it/s] \n","Processing Folder: domain=art_painting, category=dog: 100%|██████████| 348/348 [00:03<00:00, 102.02it/s]\n","Processing Folder: domain=art_painting, category=person: 100%|██████████| 404/404 [00:04<00:00, 99.85it/s] \n","Processing Folder: domain=art_painting, category=horse: 100%|██████████| 179/179 [00:01<00:00, 105.06it/s]\n","Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 227/227 [00:02<00:00, 103.39it/s]\n","Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 169/169 [00:01<00:00, 103.10it/s]\n","Processing Folder: domain=sketch, category=elephant: 100%|██████████| 674/674 [00:06<00:00, 103.58it/s]\n","Processing Folder: domain=sketch, category=guitar: 100%|██████████| 564/564 [00:06<00:00, 89.61it/s] \n","Processing Folder: domain=sketch, category=dog: 100%|██████████| 697/697 [00:07<00:00, 98.76it/s] \n","Processing Folder: domain=sketch, category=horse: 100%|██████████| 736/736 [00:08<00:00, 89.65it/s]\n","Processing Folder: domain=sketch, category=house: 100%|██████████| 75/75 [00:00<00:00, 102.78it/s]\n","Processing Folder: domain=sketch, category=person: 100%|██████████| 143/143 [00:01<00:00, 94.33it/s] \n","Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 681/681 [00:07<00:00, 96.35it/s] \n","Processing Folder: domain=cartoon, category=dog: 100%|██████████| 343/343 [00:03<00:00, 96.40it/s] \n","Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 314/314 [00:03<00:00, 87.05it/s]\n","Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 411/411 [00:05<00:00, 69.00it/s]\n","Processing Folder: domain=cartoon, category=horse: 100%|██████████| 299/299 [00:04<00:00, 74.35it/s]\n","Processing Folder: domain=cartoon, category=person: 100%|██████████| 364/364 [00:05<00:00, 68.41it/s]\n","Processing Folder: domain=cartoon, category=house: 100%|██████████| 266/266 [00:02<00:00, 97.55it/s] \n","Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 123/123 [00:01<00:00, 99.75it/s] \n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Processing Folder: domain=art_painting, category=dog: 100%|██████████| 31/31 [00:02<00:00, 10.89it/s]\n","Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 28/28 [00:00<00:00, 56.00it/s]\n","Processing Folder: domain=art_painting, category=horse: 100%|██████████| 22/22 [00:00<00:00, 80.37it/s]\n","Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 31/31 [00:00<00:00, 57.04it/s]\n","Processing Folder: domain=art_painting, category=house: 100%|██████████| 33/33 [00:00<00:00, 79.63it/s]\n","Processing Folder: domain=art_painting, category=person: 100%|██████████| 45/45 [00:00<00:00, 72.38it/s]\n","Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 15/15 [00:00<00:00, 90.70it/s]\n","Processing Folder: domain=cartoon, category=dog: 100%|██████████| 46/46 [00:00<00:00, 110.84it/s]\n","Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 12/12 [00:00<00:00, 112.61it/s]\n","Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 32/32 [00:00<00:00, 110.41it/s]\n","Processing Folder: domain=cartoon, category=horse: 100%|██████████| 25/25 [00:00<00:00, 100.87it/s]\n","Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 46/46 [00:00<00:00, 105.13it/s]\n","Processing Folder: domain=cartoon, category=person: 100%|██████████| 41/41 [00:00<00:00, 100.34it/s]\n","Processing Folder: domain=cartoon, category=house: 100%|██████████| 22/22 [00:00<00:00, 105.45it/s]\n","Processing Folder: domain=photo, category=dog: 100%|██████████| 20/20 [00:00<00:00, 100.46it/s]\n","Processing Folder: domain=photo, category=elephant: 100%|██████████| 21/21 [00:00<00:00, 89.34it/s]\n","Processing Folder: domain=photo, category=person: 100%|██████████| 49/49 [00:00<00:00, 98.55it/s]\n","Processing Folder: domain=photo, category=guitar: 100%|██████████| 19/19 [00:00<00:00, 100.96it/s]\n","Processing Folder: domain=photo, category=giraffe: 100%|██████████| 17/17 [00:00<00:00, 102.87it/s]\n","Processing Folder: domain=photo, category=house: 100%|██████████| 37/37 [00:00<00:00, 103.38it/s]\n","Processing Folder: domain=photo, category=horse: 100%|██████████| 13/13 [00:00<00:00, 99.26it/s]\n","Processing Folder: domain=sketch, category=dog: 100%|██████████| 75/75 [00:00<00:00, 107.05it/s]\n","Processing Folder: domain=sketch, category=guitar: 100%|██████████| 44/44 [00:00<00:00, 104.03it/s]\n","Processing Folder: domain=sketch, category=person: 100%|██████████| 17/17 [00:00<00:00, 91.66it/s]\n","Processing Folder: domain=sketch, category=house: 100%|██████████| 5/5 [00:00<00:00, 114.35it/s]\n","Processing Folder: domain=sketch, category=elephant: 100%|██████████| 66/66 [00:00<00:00, 102.79it/s]\n","Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 72/72 [00:00<00:00, 108.47it/s]\n","Processing Folder: domain=sketch, category=horse: 100%|██████████| 80/80 [00:00<00:00, 101.64it/s]\n"]}]},{"cell_type":"code","source":["LABEL_SIZE = {'domain': 4, 'category': 7}\n","label_type = 'domain'\n","epochs = 100\n","lr=1e-3\n","weight_decay=0\n","\n","\n","best_model = None\n","best_acc = 0.0\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","experiment_name = 'experiments/{}/{}_lr_{}.wd_{}'.format(\n","    'exp', 'domain', 1e-3, 0)\n","\n","os.makedirs(experiment_name, exist_ok=True)\n","writer = SummaryWriter(log_dir=experiment_name)\n","\n","configs = {'num_classes': LABEL_SIZE['domain', 'category']}\n","\n","############################################################################\n","\"\"\"After implementing all required models, you can switch from here.\"\"\"\n","model = AlexNet(configs).to(device)\n","# model = AlexNetLargeKernel(configs).to(device)\n","# model = AlexNetAvgPooling(configs).to(device)\n","############################################################################\n","\n","print('Model Architecture:\\n%s' % model)\n","\n","criterion = nn.CrossEntropyLoss(reduction='mean')\n","optimizer = torch.optim.Adam(model.parameters(),\n","                              lr=lr,\n","                              weight_decay=weight_decay)\n","\n","try:\n","  for epoch in range(epochs):\n","    for phase in ('train', 'eval'):\n","      if phase == 'train':\n","        model.train()\n","        dataset = train_dataset\n","        data_loader = train_loader\n","      else:\n","        model.eval()\n","        dataset = val_dataset\n","        data_loader = val_loader\n","\n","      running_loss = 0.0\n","      running_corrects = 0\n","\n","      for step, (images, labels) in enumerate(data_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        with torch.set_grad_enabled(phase == 'train'):\n","          outputs = model(images)\n","          _, preds = torch.max(outputs, 1)\n","          loss = criterion(outputs, labels)\n","\n","          if phase == 'train':\n","            loss.backward()\n","            optimizer.step()\n","\n","            writer.add_scalar('Loss/{}'.format(phase), loss.item(),\n","                              epoch * len(data_loader) + step)\n","\n","        running_loss += loss.item() * images.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","\n","      epoch_loss = running_loss / len(dataset)\n","      epoch_acc = running_corrects.double() / len(dataset)\n","      writer.add_scalar('Epoch_Loss/{}'.format(phase), epoch_loss, epoch)\n","      writer.add_scalar('Epoch_Accuracy/{}'.format(phase), epoch_acc, epoch)\n","      print('[Epoch %d] %s accuracy: %.4f, loss: %.4f' %\n","            (epoch + 1, phase, epoch_acc, epoch_loss))\n","\n","      if phase == 'eval':\n","        if epoch_acc > best_acc:\n","          best_acc = epoch_acc\n","          best_model = copy.deepcopy(model.state_dict())\n","          torch.save(best_model, os.path.join(experiment_name, 'best_model.pt'))\n","except KeyboardInterrupt:\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3PVBhC84YxJ4","executionInfo":{"status":"ok","timestamp":1651594622768,"user_tz":300,"elapsed":3212730,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}},"outputId":"7f828f5b-1415-4024-cadb-1450d57e0b88"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Architecture:\n","AlexNet(\n","  (loss): CrossEntropyLoss()\n","  (train_acc): Accuracy()\n","  (val_acc): Accuracy()\n","  (features): Sequential(\n","    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU()\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU()\n","    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU()\n","    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU()\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=-1, end_dim=-1)\n","    (1): Dropout(p=0.2, inplace=False)\n","    (2): Linear(in_features=9216, out_features=4096, bias=True)\n","    (3): ReLU()\n","    (4): Dropout(p=0.2, inplace=False)\n","    (5): Linear(in_features=4096, out_features=4096, bias=True)\n","    (6): ReLU()\n","    (7): Linear(in_features=4096, out_features=28, bias=True)\n","  )\n",")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch 1] train accuracy: 0.5176, loss: 2.0146\n","[Epoch 1] eval accuracy: 0.7210, loss: 0.5808\n","[Epoch 2] train accuracy: 0.7534, loss: 0.5599\n","[Epoch 2] eval accuracy: 0.7510, loss: 0.5494\n","[Epoch 3] train accuracy: 0.7782, loss: 0.5006\n","[Epoch 3] eval accuracy: 0.7790, loss: 0.4499\n","[Epoch 4] train accuracy: 0.7884, loss: 0.5161\n","[Epoch 4] eval accuracy: 0.7905, loss: 0.5580\n","[Epoch 5] train accuracy: 0.8006, loss: 0.4998\n","[Epoch 5] eval accuracy: 0.8143, loss: 0.4538\n","[Epoch 6] train accuracy: 0.8122, loss: 0.4536\n","[Epoch 6] eval accuracy: 0.8133, loss: 0.4488\n","[Epoch 7] train accuracy: 0.8244, loss: 0.4251\n","[Epoch 7] eval accuracy: 0.8257, loss: 0.4128\n","[Epoch 8] train accuracy: 0.8351, loss: 0.3980\n","[Epoch 8] eval accuracy: 0.8247, loss: 0.3885\n","[Epoch 9] train accuracy: 0.8420, loss: 0.3703\n","[Epoch 9] eval accuracy: 0.8278, loss: 0.3837\n","[Epoch 10] train accuracy: 0.8553, loss: 0.3448\n","[Epoch 10] eval accuracy: 0.8257, loss: 0.3582\n","[Epoch 11] train accuracy: 0.8693, loss: 0.3106\n","[Epoch 11] eval accuracy: 0.8371, loss: 0.3951\n","[Epoch 12] train accuracy: 0.8749, loss: 0.2942\n","[Epoch 12] eval accuracy: 0.8320, loss: 0.3934\n","[Epoch 13] train accuracy: 0.8871, loss: 0.2726\n","[Epoch 13] eval accuracy: 0.8361, loss: 0.3706\n","[Epoch 14] train accuracy: 0.8983, loss: 0.2475\n","[Epoch 14] eval accuracy: 0.8382, loss: 0.4051\n","[Epoch 15] train accuracy: 0.9016, loss: 0.2367\n","[Epoch 15] eval accuracy: 0.8413, loss: 0.4330\n","[Epoch 16] train accuracy: 0.9163, loss: 0.2050\n","[Epoch 16] eval accuracy: 0.8340, loss: 0.4847\n","[Epoch 17] train accuracy: 0.9236, loss: 0.1941\n","[Epoch 17] eval accuracy: 0.8454, loss: 0.4917\n","[Epoch 18] train accuracy: 0.9276, loss: 0.1810\n","[Epoch 18] eval accuracy: 0.8444, loss: 0.4418\n","[Epoch 19] train accuracy: 0.9367, loss: 0.1584\n","[Epoch 19] eval accuracy: 0.8537, loss: 0.5773\n","[Epoch 20] train accuracy: 0.9379, loss: 0.1550\n","[Epoch 20] eval accuracy: 0.8454, loss: 0.5994\n","[Epoch 21] train accuracy: 0.9434, loss: 0.1481\n","[Epoch 21] eval accuracy: 0.8475, loss: 0.6524\n","[Epoch 22] train accuracy: 0.9468, loss: 0.1363\n","[Epoch 22] eval accuracy: 0.8568, loss: 0.5980\n","[Epoch 23] train accuracy: 0.9516, loss: 0.1254\n","[Epoch 23] eval accuracy: 0.8382, loss: 0.6589\n","[Epoch 24] train accuracy: 0.9537, loss: 0.1163\n","[Epoch 24] eval accuracy: 0.8434, loss: 0.5719\n","[Epoch 25] train accuracy: 0.9651, loss: 0.0916\n","[Epoch 25] eval accuracy: 0.8434, loss: 0.7077\n","[Epoch 26] train accuracy: 0.9665, loss: 0.0921\n","[Epoch 26] eval accuracy: 0.8485, loss: 0.6338\n","[Epoch 27] train accuracy: 0.9648, loss: 0.0928\n","[Epoch 27] eval accuracy: 0.8475, loss: 0.7455\n","[Epoch 28] train accuracy: 0.9739, loss: 0.0732\n","[Epoch 28] eval accuracy: 0.8268, loss: 0.8754\n","[Epoch 29] train accuracy: 0.9716, loss: 0.0781\n","[Epoch 29] eval accuracy: 0.8371, loss: 1.0028\n","[Epoch 30] train accuracy: 0.9693, loss: 0.0886\n","[Epoch 30] eval accuracy: 0.8465, loss: 0.7250\n","[Epoch 31] train accuracy: 0.9742, loss: 0.0733\n","[Epoch 31] eval accuracy: 0.8226, loss: 0.7771\n","[Epoch 32] train accuracy: 0.9754, loss: 0.0681\n","[Epoch 32] eval accuracy: 0.8320, loss: 0.7824\n","[Epoch 33] train accuracy: 0.9843, loss: 0.0475\n","[Epoch 33] eval accuracy: 0.8465, loss: 0.8689\n","[Epoch 34] train accuracy: 0.9880, loss: 0.0392\n","[Epoch 34] eval accuracy: 0.8320, loss: 1.0396\n","[Epoch 35] train accuracy: 0.9818, loss: 0.0561\n","[Epoch 35] eval accuracy: 0.8413, loss: 0.8522\n","[Epoch 36] train accuracy: 0.9807, loss: 0.0590\n","[Epoch 36] eval accuracy: 0.8330, loss: 0.9006\n","[Epoch 37] train accuracy: 0.9859, loss: 0.0438\n","[Epoch 37] eval accuracy: 0.8288, loss: 1.0551\n","[Epoch 38] train accuracy: 0.9864, loss: 0.0450\n","[Epoch 38] eval accuracy: 0.8527, loss: 1.1017\n","[Epoch 39] train accuracy: 0.9829, loss: 0.0572\n","[Epoch 39] eval accuracy: 0.8517, loss: 0.8038\n","[Epoch 40] train accuracy: 0.9863, loss: 0.0386\n","[Epoch 40] eval accuracy: 0.8382, loss: 0.9661\n","[Epoch 41] train accuracy: 0.9765, loss: 0.0788\n","[Epoch 41] eval accuracy: 0.8268, loss: 0.7414\n","[Epoch 42] train accuracy: 0.9881, loss: 0.0379\n","[Epoch 42] eval accuracy: 0.8517, loss: 0.8622\n","[Epoch 43] train accuracy: 0.9888, loss: 0.0327\n","[Epoch 43] eval accuracy: 0.8517, loss: 0.9160\n","[Epoch 44] train accuracy: 0.9837, loss: 0.0475\n","[Epoch 44] eval accuracy: 0.8371, loss: 0.9470\n","[Epoch 45] train accuracy: 0.9806, loss: 0.0610\n","[Epoch 45] eval accuracy: 0.8402, loss: 0.7495\n","[Epoch 46] train accuracy: 0.9874, loss: 0.0421\n","[Epoch 46] eval accuracy: 0.8485, loss: 0.8647\n","[Epoch 47] train accuracy: 0.9905, loss: 0.0293\n","[Epoch 47] eval accuracy: 0.8485, loss: 0.9649\n","[Epoch 48] train accuracy: 0.9876, loss: 0.0464\n","[Epoch 48] eval accuracy: 0.8454, loss: 0.9352\n","[Epoch 49] train accuracy: 0.9912, loss: 0.0290\n","[Epoch 49] eval accuracy: 0.8527, loss: 1.0278\n","[Epoch 50] train accuracy: 0.9930, loss: 0.0213\n","[Epoch 50] eval accuracy: 0.8485, loss: 0.9786\n","[Epoch 51] train accuracy: 0.9930, loss: 0.0250\n","[Epoch 51] eval accuracy: 0.8537, loss: 1.0273\n","[Epoch 52] train accuracy: 0.9869, loss: 0.0414\n","[Epoch 52] eval accuracy: 0.8465, loss: 0.9896\n","[Epoch 53] train accuracy: 0.9893, loss: 0.0333\n","[Epoch 53] eval accuracy: 0.8340, loss: 1.4181\n","[Epoch 54] train accuracy: 0.9857, loss: 0.0519\n","[Epoch 54] eval accuracy: 0.8351, loss: 1.0991\n","[Epoch 55] train accuracy: 0.9839, loss: 0.0527\n","[Epoch 55] eval accuracy: 0.8340, loss: 1.0447\n","[Epoch 56] train accuracy: 0.9912, loss: 0.0321\n","[Epoch 56] eval accuracy: 0.8309, loss: 1.1106\n","[Epoch 57] train accuracy: 0.9939, loss: 0.0224\n","[Epoch 57] eval accuracy: 0.8548, loss: 1.0584\n","[Epoch 58] train accuracy: 0.9920, loss: 0.0269\n","[Epoch 58] eval accuracy: 0.8506, loss: 0.9442\n","[Epoch 59] train accuracy: 0.9946, loss: 0.0173\n","[Epoch 59] eval accuracy: 0.8465, loss: 1.3974\n","[Epoch 60] train accuracy: 0.9938, loss: 0.0230\n","[Epoch 60] eval accuracy: 0.8506, loss: 1.2415\n","[Epoch 61] train accuracy: 0.9939, loss: 0.0196\n","[Epoch 61] eval accuracy: 0.8527, loss: 1.1190\n","[Epoch 62] train accuracy: 0.9890, loss: 0.0374\n","[Epoch 62] eval accuracy: 0.8444, loss: 1.1444\n","[Epoch 63] train accuracy: 0.9900, loss: 0.0345\n","[Epoch 63] eval accuracy: 0.8454, loss: 0.9624\n","[Epoch 64] train accuracy: 0.9920, loss: 0.0271\n","[Epoch 64] eval accuracy: 0.8548, loss: 1.0956\n","[Epoch 65] train accuracy: 0.9934, loss: 0.0256\n","[Epoch 65] eval accuracy: 0.8402, loss: 1.0712\n","[Epoch 66] train accuracy: 0.9946, loss: 0.0218\n","[Epoch 66] eval accuracy: 0.8506, loss: 1.2521\n","[Epoch 67] train accuracy: 0.9900, loss: 0.0375\n","[Epoch 67] eval accuracy: 0.8402, loss: 1.1397\n","[Epoch 68] train accuracy: 0.9852, loss: 0.0515\n","[Epoch 68] eval accuracy: 0.8444, loss: 1.1723\n","[Epoch 69] train accuracy: 0.9916, loss: 0.0322\n","[Epoch 69] eval accuracy: 0.8434, loss: 1.0665\n","[Epoch 70] train accuracy: 0.9908, loss: 0.0303\n","[Epoch 70] eval accuracy: 0.8537, loss: 1.1815\n","[Epoch 71] train accuracy: 0.9895, loss: 0.0323\n","[Epoch 71] eval accuracy: 0.8485, loss: 1.0858\n","[Epoch 72] train accuracy: 0.9915, loss: 0.0321\n","[Epoch 72] eval accuracy: 0.8537, loss: 1.0663\n","[Epoch 73] train accuracy: 0.9880, loss: 0.0409\n","[Epoch 73] eval accuracy: 0.8454, loss: 1.0556\n","[Epoch 74] train accuracy: 0.9925, loss: 0.0257\n","[Epoch 74] eval accuracy: 0.8485, loss: 1.0802\n","[Epoch 75] train accuracy: 0.9916, loss: 0.0339\n","[Epoch 75] eval accuracy: 0.8506, loss: 0.8871\n","[Epoch 76] train accuracy: 0.9825, loss: 0.0590\n","[Epoch 76] eval accuracy: 0.8517, loss: 0.7974\n","[Epoch 77] train accuracy: 0.9928, loss: 0.0229\n","[Epoch 77] eval accuracy: 0.8454, loss: 1.2145\n","[Epoch 78] train accuracy: 0.9927, loss: 0.0277\n","[Epoch 78] eval accuracy: 0.8309, loss: 0.9864\n","[Epoch 79] train accuracy: 0.9931, loss: 0.0276\n","[Epoch 79] eval accuracy: 0.8392, loss: 1.3160\n","[Epoch 80] train accuracy: 0.9930, loss: 0.0292\n","[Epoch 80] eval accuracy: 0.8278, loss: 0.9210\n","[Epoch 81] train accuracy: 0.9922, loss: 0.0289\n","[Epoch 81] eval accuracy: 0.8485, loss: 0.9793\n","[Epoch 82] train accuracy: 0.9953, loss: 0.0153\n","[Epoch 82] eval accuracy: 0.8558, loss: 1.3611\n","[Epoch 83] train accuracy: 0.9904, loss: 0.0356\n","[Epoch 83] eval accuracy: 0.8475, loss: 0.9427\n","[Epoch 84] train accuracy: 0.9917, loss: 0.0324\n","[Epoch 84] eval accuracy: 0.8506, loss: 0.7458\n","[Epoch 85] train accuracy: 0.9938, loss: 0.0222\n","[Epoch 85] eval accuracy: 0.8413, loss: 0.9851\n","[Epoch 86] train accuracy: 0.9968, loss: 0.0141\n","[Epoch 86] eval accuracy: 0.8506, loss: 1.4910\n","[Epoch 87] train accuracy: 0.9942, loss: 0.0205\n","[Epoch 87] eval accuracy: 0.8475, loss: 1.1245\n","[Epoch 88] train accuracy: 0.9934, loss: 0.0255\n","[Epoch 88] eval accuracy: 0.8496, loss: 1.1425\n","[Epoch 89] train accuracy: 0.9958, loss: 0.0167\n","[Epoch 89] eval accuracy: 0.8496, loss: 1.2308\n","[Epoch 90] train accuracy: 0.9947, loss: 0.0204\n","[Epoch 90] eval accuracy: 0.8413, loss: 1.0415\n","[Epoch 91] train accuracy: 0.9866, loss: 0.0475\n","[Epoch 91] eval accuracy: 0.8475, loss: 1.1858\n","[Epoch 92] train accuracy: 0.9897, loss: 0.0408\n","[Epoch 92] eval accuracy: 0.8382, loss: 1.0330\n","[Epoch 93] train accuracy: 0.9945, loss: 0.0211\n","[Epoch 93] eval accuracy: 0.8496, loss: 1.2463\n","[Epoch 94] train accuracy: 0.9957, loss: 0.0199\n","[Epoch 94] eval accuracy: 0.8517, loss: 1.2083\n","[Epoch 95] train accuracy: 0.9958, loss: 0.0163\n","[Epoch 95] eval accuracy: 0.8434, loss: 1.2614\n","[Epoch 96] train accuracy: 0.9917, loss: 0.0376\n","[Epoch 96] eval accuracy: 0.8413, loss: 1.0133\n","[Epoch 97] train accuracy: 0.9921, loss: 0.0304\n","[Epoch 97] eval accuracy: 0.8299, loss: 1.0943\n","[Epoch 98] train accuracy: 0.9942, loss: 0.0192\n","[Epoch 98] eval accuracy: 0.8423, loss: 1.1812\n","[Epoch 99] train accuracy: 0.9927, loss: 0.0324\n","[Epoch 99] eval accuracy: 0.8465, loss: 1.0853\n","[Epoch 100] train accuracy: 0.9924, loss: 0.0259\n","[Epoch 100] eval accuracy: 0.8454, loss: 1.1789\n"]}]},{"cell_type":"code","source":["root_dir='/content/drive/MyDrive/DL/HW2/pacs_dataset'\n","\n","'''# Hyperparameters for Part I\n","flags.DEFINE_float('learning_rate', 1e-3, 'Learning rate.')\n","flags.DEFINE_float('weight_decay', 0, 'Weight decay (L2 regularization).')\n","flags.DEFINE_integer('batch_size', 128, 'Number of examples per batch.')\n","flags.DEFINE_integer('epochs', 100, 'Number of epochs for training.')\n","flags.DEFINE_string('experiment_name', 'exp', 'Defines experiment name.')\n","flags.DEFINE_enum('label_type', 'domain', ['domain', 'category'],\n","                  'Specifies prediction task.')\n","                  \n","LABEL_SIZE = {'domain': 4, 'category': 7}'''\n","\n","train_dataset_cat = PACSDataset(root_dir=root_dir,\n","                              label_type='category',\n","                              is_training=True)\n","train_loader_cat = DataLoader(train_dataset,\n","                          batch_size=128,\n","                          shuffle=True,\n","                          num_workers=4)\n","\n","val_dataset_cat = PACSDataset(root_dir=root_dir,\n","                          label_type='category',\n","                          is_training=False)\n","val_loader_cat = DataLoader(val_dataset,\n","                        batch_size=128,\n","                        shuffle=False,\n","                        num_workers=4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Bwp7980Lvmhj","executionInfo":{"status":"ok","timestamp":1651595456824,"user_tz":300,"elapsed":101896,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}},"outputId":"b7bb4551-d0f8-4901-cffa-eb3187715f0a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Processing Folder: domain=photo, category=dog: 100%|██████████| 169/169 [00:01<00:00, 92.45it/s] \n","Processing Folder: domain=photo, category=elephant: 100%|██████████| 181/181 [00:01<00:00, 96.99it/s] \n","Processing Folder: domain=photo, category=giraffe: 100%|██████████| 165/165 [00:01<00:00, 94.62it/s] \n","Processing Folder: domain=photo, category=horse: 100%|██████████| 186/186 [00:01<00:00, 95.10it/s] \n","Processing Folder: domain=photo, category=guitar: 100%|██████████| 167/167 [00:01<00:00, 98.69it/s] \n","Processing Folder: domain=photo, category=house: 100%|██████████| 243/243 [00:02<00:00, 98.03it/s] \n","Processing Folder: domain=photo, category=person: 100%|██████████| 383/383 [00:04<00:00, 94.22it/s] \n","Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 254/254 [00:02<00:00, 96.75it/s] \n","Processing Folder: domain=art_painting, category=house: 100%|██████████| 262/262 [00:02<00:00, 94.50it/s] \n","Processing Folder: domain=art_painting, category=dog: 100%|██████████| 348/348 [00:03<00:00, 97.39it/s] \n","Processing Folder: domain=art_painting, category=person: 100%|██████████| 404/404 [00:04<00:00, 96.28it/s] \n","Processing Folder: domain=art_painting, category=horse: 100%|██████████| 179/179 [00:01<00:00, 92.94it/s] \n","Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 227/227 [00:02<00:00, 95.68it/s] \n","Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 169/169 [00:01<00:00, 97.50it/s] \n","Processing Folder: domain=sketch, category=elephant: 100%|██████████| 674/674 [00:06<00:00, 99.07it/s] \n","Processing Folder: domain=sketch, category=guitar: 100%|██████████| 564/564 [00:05<00:00, 97.34it/s] \n","Processing Folder: domain=sketch, category=dog: 100%|██████████| 697/697 [00:07<00:00, 95.53it/s] \n","Processing Folder: domain=sketch, category=horse: 100%|██████████| 736/736 [00:07<00:00, 104.04it/s]\n","Processing Folder: domain=sketch, category=house: 100%|██████████| 75/75 [00:00<00:00, 92.61it/s]\n","Processing Folder: domain=sketch, category=person: 100%|██████████| 143/143 [00:01<00:00, 77.80it/s]\n","Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 681/681 [00:06<00:00, 100.64it/s]\n","Processing Folder: domain=cartoon, category=dog: 100%|██████████| 343/343 [00:03<00:00, 107.92it/s]\n","Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 314/314 [00:03<00:00, 96.23it/s] \n","Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 411/411 [00:03<00:00, 106.55it/s]\n","Processing Folder: domain=cartoon, category=horse: 100%|██████████| 299/299 [00:02<00:00, 105.53it/s]\n","Processing Folder: domain=cartoon, category=person: 100%|██████████| 364/364 [00:03<00:00, 103.08it/s]\n","Processing Folder: domain=cartoon, category=house: 100%|██████████| 266/266 [00:02<00:00, 103.55it/s]\n","Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 123/123 [00:01<00:00, 108.08it/s]\n","/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n","Processing Folder: domain=art_painting, category=dog: 100%|██████████| 31/31 [00:00<00:00, 102.89it/s]\n","Processing Folder: domain=art_painting, category=elephant: 100%|██████████| 28/28 [00:00<00:00, 101.48it/s]\n","Processing Folder: domain=art_painting, category=horse: 100%|██████████| 22/22 [00:00<00:00, 107.12it/s]\n","Processing Folder: domain=art_painting, category=giraffe: 100%|██████████| 31/31 [00:00<00:00, 99.52it/s] \n","Processing Folder: domain=art_painting, category=house: 100%|██████████| 33/33 [00:00<00:00, 98.72it/s] \n","Processing Folder: domain=art_painting, category=person: 100%|██████████| 45/45 [00:00<00:00, 109.28it/s]\n","Processing Folder: domain=art_painting, category=guitar: 100%|██████████| 15/15 [00:00<00:00, 92.17it/s]\n","Processing Folder: domain=cartoon, category=dog: 100%|██████████| 46/46 [00:00<00:00, 99.53it/s] \n","Processing Folder: domain=cartoon, category=guitar: 100%|██████████| 12/12 [00:00<00:00, 98.00it/s] \n","Processing Folder: domain=cartoon, category=giraffe: 100%|██████████| 32/32 [00:00<00:00, 113.86it/s]\n","Processing Folder: domain=cartoon, category=horse: 100%|██████████| 25/25 [00:00<00:00, 101.84it/s]\n","Processing Folder: domain=cartoon, category=elephant: 100%|██████████| 46/46 [00:00<00:00, 100.47it/s]\n","Processing Folder: domain=cartoon, category=person: 100%|██████████| 41/41 [00:00<00:00, 104.61it/s]\n","Processing Folder: domain=cartoon, category=house: 100%|██████████| 22/22 [00:00<00:00, 110.44it/s]\n","Processing Folder: domain=photo, category=dog: 100%|██████████| 20/20 [00:00<00:00, 110.27it/s]\n","Processing Folder: domain=photo, category=elephant: 100%|██████████| 21/21 [00:00<00:00, 106.67it/s]\n","Processing Folder: domain=photo, category=person: 100%|██████████| 49/49 [00:00<00:00, 99.15it/s]\n","Processing Folder: domain=photo, category=guitar: 100%|██████████| 19/19 [00:00<00:00, 105.59it/s]\n","Processing Folder: domain=photo, category=giraffe: 100%|██████████| 17/17 [00:00<00:00, 100.20it/s]\n","Processing Folder: domain=photo, category=house: 100%|██████████| 37/37 [00:00<00:00, 102.99it/s]\n","Processing Folder: domain=photo, category=horse: 100%|██████████| 13/13 [00:00<00:00, 97.82it/s]\n","Processing Folder: domain=sketch, category=dog: 100%|██████████| 75/75 [00:00<00:00, 104.59it/s]\n","Processing Folder: domain=sketch, category=guitar: 100%|██████████| 44/44 [00:00<00:00, 109.94it/s]\n","Processing Folder: domain=sketch, category=person: 100%|██████████| 17/17 [00:00<00:00, 102.01it/s]\n","Processing Folder: domain=sketch, category=house: 100%|██████████| 5/5 [00:00<00:00, 109.98it/s]\n","Processing Folder: domain=sketch, category=elephant: 100%|██████████| 66/66 [00:00<00:00, 104.73it/s]\n","Processing Folder: domain=sketch, category=giraffe: 100%|██████████| 72/72 [00:00<00:00, 106.22it/s]\n","Processing Folder: domain=sketch, category=horse: 100%|██████████| 80/80 [00:00<00:00, 102.72it/s]\n"]}]},{"cell_type":"code","source":["LABEL_SIZE = {'domain': 4, 'category': 7}\n","label_type = 'category'\n","epochs = 50\n","lr=1e-3\n","weight_decay=0\n","\n","\n","best_model_cat = None\n","best_acc = 0.0\n","\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","experiment_name = 'experiments/{}/{}_lr_{}.wd_{}'.format(\n","    'exp', 'category', 1e-3, 0)\n","\n","os.makedirs(experiment_name, exist_ok=True)\n","writer = SummaryWriter(log_dir=experiment_name)\n","\n","configs = {'num_classes': LABEL_SIZE['category']}\n","\n","############################################################################\n","\"\"\"After implementing all required models, you can switch from here.\"\"\"\n","model = AlexNet(configs).to(device)\n","# model = AlexNetLargeKernel(configs).to(device)\n","# model = AlexNetAvgPooling(configs).to(device)\n","############################################################################\n","\n","print('Model Architecture:\\n%s' % model)\n","\n","criterion = nn.CrossEntropyLoss(reduction='mean')\n","optimizer = torch.optim.Adam(model.parameters(),\n","                              lr=lr,\n","                              weight_decay=weight_decay)\n","\n","try:\n","  for epoch in range(epochs):\n","    for phase in ('train', 'eval'):\n","      if phase == 'train':\n","        model.train()\n","        dataset = train_dataset\n","        data_loader = train_loader\n","      else:\n","        model.eval()\n","        dataset = val_dataset\n","        data_loader = val_loader\n","\n","      running_loss = 0.0\n","      running_corrects = 0\n","\n","      for step, (images, labels) in enumerate(data_loader):\n","        images = images.to(device)\n","        labels = labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        with torch.set_grad_enabled(phase == 'train'):\n","          outputs = model(images)\n","          _, preds = torch.max(outputs, 1)\n","          loss = criterion(outputs, labels)\n","\n","          if phase == 'train':\n","            loss.backward()\n","            optimizer.step()\n","\n","            writer.add_scalar('Loss/{}'.format(phase), loss.item(),\n","                              epoch * len(data_loader) + step)\n","\n","        running_loss += loss.item() * images.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","\n","      epoch_loss = running_loss / len(dataset)\n","      epoch_acc = running_corrects.double() / len(dataset)\n","      writer.add_scalar('Epoch_Loss/{}'.format(phase), epoch_loss, epoch)\n","      writer.add_scalar('Epoch_Accuracy/{}'.format(phase), epoch_acc, epoch)\n","      print('[Epoch %d] %s accuracy: %.4f, loss: %.4f' %\n","            (epoch + 1, phase, epoch_acc, epoch_loss))\n","\n","      if phase == 'eval':\n","        if epoch_acc > best_acc:\n","          best_acc = epoch_acc\n","          best_model_cat = copy.deepcopy(model.state_dict())\n","          torch.save(best_model_cat, os.path.join(experiment_name, 'best_model_cat.pt'))\n","except KeyboardInterrupt:\n","    pass"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BVfOKEHrwJud","executionInfo":{"status":"ok","timestamp":1651596934207,"user_tz":300,"elapsed":1477134,"user":{"displayName":"Truc Nguyen","userId":"01695833024010148463"}},"outputId":"b52e3806-f3fc-4b10-a9da-d0f987019332"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model Architecture:\n","AlexNet(\n","  (loss): CrossEntropyLoss()\n","  (train_acc): Accuracy()\n","  (val_acc): Accuracy()\n","  (features): Sequential(\n","    (0): Conv2d(3, 96, kernel_size=(11, 11), stride=(4, 4))\n","    (1): ReLU()\n","    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (3): Conv2d(96, 256, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n","    (4): ReLU()\n","    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (6): Conv2d(256, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (7): ReLU()\n","    (8): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (9): ReLU()\n","    (10): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU()\n","    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (classifier): Sequential(\n","    (0): Flatten(start_dim=-1, end_dim=-1)\n","    (1): Dropout(p=0.2, inplace=False)\n","    (2): Linear(in_features=9216, out_features=4096, bias=True)\n","    (3): ReLU()\n","    (4): Dropout(p=0.2, inplace=False)\n","    (5): Linear(in_features=4096, out_features=4096, bias=True)\n","    (6): ReLU()\n","    (7): Linear(in_features=4096, out_features=28, bias=True)\n","  )\n",")\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["[Epoch 1] train accuracy: 0.5474, loss: 1.9022\n","[Epoch 1] eval accuracy: 0.7718, loss: 0.5308\n","[Epoch 2] train accuracy: 0.7656, loss: 0.5426\n","[Epoch 2] eval accuracy: 0.7573, loss: 0.5705\n","[Epoch 3] train accuracy: 0.7830, loss: 0.5213\n","[Epoch 3] eval accuracy: 0.7936, loss: 0.4759\n","[Epoch 4] train accuracy: 0.7978, loss: 0.4913\n","[Epoch 4] eval accuracy: 0.7967, loss: 0.4731\n","[Epoch 5] train accuracy: 0.7976, loss: 0.4827\n","[Epoch 5] eval accuracy: 0.8154, loss: 0.4403\n","[Epoch 6] train accuracy: 0.8219, loss: 0.4254\n","[Epoch 6] eval accuracy: 0.8444, loss: 0.3788\n","[Epoch 7] train accuracy: 0.8355, loss: 0.4008\n","[Epoch 7] eval accuracy: 0.8278, loss: 0.4295\n","[Epoch 8] train accuracy: 0.8347, loss: 0.4171\n","[Epoch 8] eval accuracy: 0.8288, loss: 0.3881\n","[Epoch 9] train accuracy: 0.8513, loss: 0.3653\n","[Epoch 9] eval accuracy: 0.8496, loss: 0.3543\n","[Epoch 10] train accuracy: 0.8294, loss: 0.4457\n","[Epoch 10] eval accuracy: 0.8216, loss: 0.4258\n","[Epoch 11] train accuracy: 0.8450, loss: 0.3951\n","[Epoch 11] eval accuracy: 0.8558, loss: 0.3861\n","[Epoch 12] train accuracy: 0.8528, loss: 0.3722\n","[Epoch 12] eval accuracy: 0.8517, loss: 0.3888\n","[Epoch 13] train accuracy: 0.8630, loss: 0.3525\n","[Epoch 13] eval accuracy: 0.8423, loss: 0.3875\n","[Epoch 14] train accuracy: 0.8728, loss: 0.3221\n","[Epoch 14] eval accuracy: 0.8579, loss: 0.3659\n","[Epoch 15] train accuracy: 0.8777, loss: 0.3031\n","[Epoch 15] eval accuracy: 0.8651, loss: 0.3601\n","[Epoch 16] train accuracy: 0.8843, loss: 0.2942\n","[Epoch 16] eval accuracy: 0.8496, loss: 0.3832\n","[Epoch 17] train accuracy: 0.8847, loss: 0.2877\n","[Epoch 17] eval accuracy: 0.8496, loss: 0.4240\n","[Epoch 18] train accuracy: 0.8892, loss: 0.2731\n","[Epoch 18] eval accuracy: 0.8558, loss: 0.3608\n","[Epoch 19] train accuracy: 0.9063, loss: 0.2315\n","[Epoch 19] eval accuracy: 0.8589, loss: 0.3712\n","[Epoch 20] train accuracy: 0.9140, loss: 0.2145\n","[Epoch 20] eval accuracy: 0.8631, loss: 0.4007\n","[Epoch 21] train accuracy: 0.9238, loss: 0.1896\n","[Epoch 21] eval accuracy: 0.8465, loss: 0.3919\n","[Epoch 22] train accuracy: 0.9263, loss: 0.1887\n","[Epoch 22] eval accuracy: 0.8527, loss: 0.4428\n","[Epoch 23] train accuracy: 0.9352, loss: 0.1762\n","[Epoch 23] eval accuracy: 0.8527, loss: 0.4356\n","[Epoch 24] train accuracy: 0.9290, loss: 0.1839\n","[Epoch 24] eval accuracy: 0.8496, loss: 0.5001\n","[Epoch 25] train accuracy: 0.9474, loss: 0.1386\n","[Epoch 25] eval accuracy: 0.8205, loss: 0.6001\n","[Epoch 26] train accuracy: 0.9503, loss: 0.1374\n","[Epoch 26] eval accuracy: 0.8423, loss: 0.5813\n","[Epoch 27] train accuracy: 0.9499, loss: 0.1394\n","[Epoch 27] eval accuracy: 0.8485, loss: 0.5422\n","[Epoch 28] train accuracy: 0.9600, loss: 0.1066\n","[Epoch 28] eval accuracy: 0.8579, loss: 0.6013\n","[Epoch 29] train accuracy: 0.9665, loss: 0.0922\n","[Epoch 29] eval accuracy: 0.8579, loss: 0.5821\n","[Epoch 30] train accuracy: 0.9673, loss: 0.0899\n","[Epoch 30] eval accuracy: 0.8485, loss: 0.6186\n","[Epoch 31] train accuracy: 0.9689, loss: 0.0881\n","[Epoch 31] eval accuracy: 0.8496, loss: 0.6857\n","[Epoch 32] train accuracy: 0.9637, loss: 0.1089\n","[Epoch 32] eval accuracy: 0.8548, loss: 0.6380\n","[Epoch 33] train accuracy: 0.9289, loss: 0.2113\n","[Epoch 33] eval accuracy: 0.8579, loss: 0.5130\n","[Epoch 34] train accuracy: 0.9637, loss: 0.1099\n","[Epoch 34] eval accuracy: 0.8465, loss: 0.6316\n","[Epoch 35] train accuracy: 0.9720, loss: 0.0809\n","[Epoch 35] eval accuracy: 0.8589, loss: 0.5922\n","[Epoch 36] train accuracy: 0.9459, loss: 0.1690\n","[Epoch 36] eval accuracy: 0.8475, loss: 0.5692\n","[Epoch 37] train accuracy: 0.9632, loss: 0.1095\n","[Epoch 37] eval accuracy: 0.8382, loss: 0.8314\n","[Epoch 38] train accuracy: 0.9771, loss: 0.0711\n","[Epoch 38] eval accuracy: 0.8631, loss: 0.7494\n","[Epoch 39] train accuracy: 0.9815, loss: 0.0621\n","[Epoch 39] eval accuracy: 0.8506, loss: 0.6669\n","[Epoch 40] train accuracy: 0.9821, loss: 0.0549\n","[Epoch 40] eval accuracy: 0.8517, loss: 0.7805\n","[Epoch 41] train accuracy: 0.9846, loss: 0.0503\n","[Epoch 41] eval accuracy: 0.8631, loss: 0.8560\n","[Epoch 42] train accuracy: 0.9836, loss: 0.0516\n","[Epoch 42] eval accuracy: 0.8610, loss: 0.8409\n","[Epoch 43] train accuracy: 0.9853, loss: 0.0484\n","[Epoch 43] eval accuracy: 0.8485, loss: 0.8495\n","[Epoch 44] train accuracy: 0.9692, loss: 0.0923\n","[Epoch 44] eval accuracy: 0.8558, loss: 0.5955\n","[Epoch 45] train accuracy: 0.9796, loss: 0.0628\n","[Epoch 45] eval accuracy: 0.8527, loss: 0.8522\n","[Epoch 46] train accuracy: 0.9816, loss: 0.0576\n","[Epoch 46] eval accuracy: 0.8454, loss: 0.7698\n","[Epoch 47] train accuracy: 0.9847, loss: 0.0524\n","[Epoch 47] eval accuracy: 0.8506, loss: 0.8802\n","[Epoch 48] train accuracy: 0.9867, loss: 0.0469\n","[Epoch 48] eval accuracy: 0.8517, loss: 0.7982\n","[Epoch 49] train accuracy: 0.9896, loss: 0.0343\n","[Epoch 49] eval accuracy: 0.8651, loss: 0.8457\n","[Epoch 50] train accuracy: 0.9906, loss: 0.0346\n","[Epoch 50] eval accuracy: 0.8620, loss: 0.8765\n"]}]},{"cell_type":"markdown","source":["# **3. Visualizing Learned Filter**"],"metadata":{"id":"SRgLqkO4sJc_"}},{"cell_type":"code","source":["def analyze_model_kernels(module, ckpt_path):\n","    loaded_model = module.load_from_checkpoint(ckpt_path)\n","    module_name = os.path.split(dirname(ckpt_path))[-1]\n","    layers = loaded_model.features\n","    for layer_num, layer in enumerate(layers):\n","        if isinstance(layer, nn.Conv2d):\n","            kernel_name = str(layer).split('(', 1)[0]\n","            kernel_weight = loaded_model.features[layer_num].weight.data\n","            visualize_kernels(kernel_name, kernel_weight, layer_num, saving_prefix=module_name)"],"metadata":{"id":"0sf_ua5sD-YB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from os.path import dirname\n","\n","\n","def visualize_kernels(kernel_name,\n","                      kernel_weight,\n","                      max_in_channels=12,\n","                      max_out_channels=12,\n","                      saving_prefix='kernel'):\n","  \"\"\"A helper function to visualize the learned convolutional kernels.\n","  \n","  Args:\n","    kernel_name: str, the name of the kernel being visualized. It will be used\n","        as the filename in the saved figures.\n","    kernel_weight: torch.Tensor or np.ndarray, the weights of convolutional\n","        kernel. The shape should be\n","        [out_channels, in_channels, kernel_height, kernel_width].\n","    max_in_channels: int, optional, the max in_channels in the visualization.\n","    max_out_channels: int, optional, the max out_channels in the visualization.\n","    saving_prefix: str, optional, the directory for saving the visualization.\n","  \"\"\"\n","  print('Visualize the learned filter of `%s`' % kernel_name)\n","  if isinstance(kernel_weight, torch.Tensor):\n","    kernel_weight = kernel_weight.cpu().numpy()\n","\n","  kernel_shape = list(kernel_weight.shape)\n","\n","  nrows = min(max_in_channels, kernel_shape[1])\n","  ncols = min(max_out_channels, kernel_shape[0])\n","\n","  fig, axes = plt.subplots(nrows, ncols, figsize=(ncols, nrows))\n","\n","  for r in range(nrows):\n","    for c in range(ncols):\n","      kernel = kernel_weight[c, r, :, :]\n","      vmin, vmax = kernel.min(), kernel.max()\n","      normalized_kernel = (kernel - vmin) / (vmax - vmin)\n","      sns.heatmap(normalized_kernel,\n","                  cbar=False,\n","                  square=True,\n","                  xticklabels=False,\n","                  yticklabels=False,\n","                  ax=axes[r, c])\n","\n","  plt.xlabel('First %d In-Channels' % nrows)\n","  plt.ylabel('First %d Out-Channels' % ncols)\n","\n","  plt.tight_layout()\n","  plt.savefig(os.path.join(saving_prefix, kernel_name.lower() + '.png'))\n","  return\n"],"metadata":{"id":"pCzUcLeY_Q7s"},"execution_count":null,"outputs":[]}]}